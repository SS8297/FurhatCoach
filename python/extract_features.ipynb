{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import glob\n",
    "import pandas as pd\n",
    "from feat import Detector\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "from feat.plotting import imshow\n",
    "from IPython.display import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [name for name in glob.glob('data/DiffusionFER/DiffusionEmotion_S/cropped/*/*/*.png')]\n",
    "detector = Detector(face_model=\"retinaface\", landmark_model= \"pfld\") # , au_model = \"xgb\", emotion_model=\"resmasknet\"\n",
    "# tested woth mobilefacenet and pfld, pfld was faster and therefore chosen\n",
    "# facial landmark detection works quite poorly for distorted faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DiffusionEmotion_S'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'data/DiffusionFER/DiffusionEmotion_S/cropped\\\\angry\\\\angry\\\\nnwotpxb_6.png'\n",
    "example.split('/')[-2]\n",
    "ex_img = cv.imread(example)\n",
    "exf = detector.detect_faces(ex_img)\n",
    "exlm = detector.detect_landmarks(ex_img, exf)\n",
    "landmarks = exlm[0][0]\n",
    "[math.dist(landmarks[33], landmark) for landmark in landmarks]\n",
    "print(len(exf[0][0]))\n",
    "image = cv.circle(ex_img, tuple(exlm[0][0][33].astype(int)), 2, [255,255,255], 3)\n",
    "image = cv.polylines(ex_img, [exlm[0][0].astype(int)], True, (255, 0, 255))\n",
    "\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Warning: NO FACE is detected\n",
      "WARNING:root:Warning: NO FACE is detected\n",
      "WARNING:root:Warning: NO FACE is detected\n",
      "WARNING:root:Warning: NO FACE is detected\n"
     ]
    }
   ],
   "source": [
    "#features, face bounding box, feature landmarks\n",
    "\n",
    "data = [extract_features(image, detector) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "fdata = list(filter(lambda sample: sample is not None, data))\n",
    "fdata = pd.DataFrame(fdata)\n",
    "fdata.to_csv(\"data/DiffusionFER/DiffusionEmotion_S/cropped/labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenates the Euclidean distance from the tip of the nose, start and end of facebox as well as image path. If no face is found the sample is discarded.\n",
    "def extract_features(path, detector):\n",
    "    img = cv.imread(path)\n",
    "    faces = detector.detect_faces(img)\n",
    "    if(len(faces[0]) == 0): return\n",
    "    landmarks = detector.detect_landmarks(img, faces)[0][0]\n",
    "    features = [math.dist(landmarks[33], landmark) for landmark in landmarks] + [faces[0][0][2] - faces[0][0][0], faces[0][0][3] - faces[0][0][1]]\n",
    "    features.append(path)\n",
    "    features.append(path.split('/')[-2])\n",
    "    return features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
